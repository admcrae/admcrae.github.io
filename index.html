<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>A McRae | Home</title>
<link rel="icon" type="image/png" href="/files/favicon.png">
<style>

  .spacedlist li + li {
    margin-top: 1ex;
  }

  #navheader {
    ul {
      list-style-type: none;
      margin: 0;
      padding: 0;
      border-bottom: solid;
    }
    li { display: inline-block; }
    li a {
      display: block;
      padding: 1ex 1em 1ex 0em;
      /* text-align: center; */
    }
  }

  body {
    max-width:45em;
    margin:auto
  }

  h1 {font-size: 1.6em;}
  h2 {font-size: 1.2em;}
  h3 {font-size: 1em;}

</style>
</head>
<body>
  <nav id="navheader">
    <ul>
      <li><a href="/">Home</a></li>
      <li><a href="/publications/">Publications</a></li>
      <!-- <li><a href="/teaching/">Teaching</a></li> -->
      <li><a href="/travel/">Travel</a></li>
    </ul>
  </nav>
  <main>
<section>
<h1>Andrew D. McRae</h1>
<ul>
    <li>E-mail: <a href="mailto:andrew.mcrae@epfl.ch">andrew.mcrae@epfl.ch</a></li>
    <li><a href="files/mcrae_cv.pdf">CV</a></li>
    <li><a href="https://people.epfl.ch/andrew.mcrae/?lang=en">EPFL directory page</a> with more contact information</li>
</ul>
</section>

<section style="text-align:justify;">
    <p>
        I am a postdoc in the <a href="https://www.epfl.ch/labs/optim/">OPTIM</a> lab at the EPFL Institute of Mathematics, advised by <a href="https://sma.epfl.ch/~nboumal/">Nicolas Boumal</a>.
        Prior to that, I graduated from Georgia Tech in May 2022 with a Ph.D. in Electrical and Computer Engineering,
        advised by <a href="https://mdav.ece.gatech.edu">Mark Davenport</a>.
    </p>
    <p>
        I am generally interested in the theory of high-dimensional statistics and signal processing and machine learning;
        my current research focuses on the <i>optimization</i> and <i>computational complexity</i> aspects of such problems.
        For many interesting estimation problems, the most natural choice of estimator requires solving a nonconvex or otherwise seemingly intractable optimization problem.
        However, these optimization problems are in practice solved well (even exactly) by convex relaxations or even direct nonconvex approaches
        (see, e.g., my recent work on synchronization problems, which resemble the famous NP-hard max-cut problem).
        I study how the <i>data models</i> from applications influence the difficulty of the associated optimization problems.
        I consider both convex and nonconvex problems and, in particular, the relationship between the two;
        we can often learn a great deal about a nonconvex problem by studying a convex relaxation of it.

        For more information on my work, see my <a href="/publications/">publications page</a> or <a href="https://scholar.google.com/citations?user=7UjxoWMAAAAJ">Google Scholar profile</a>.
    </p>
</section>
</main>

</body>
</html>